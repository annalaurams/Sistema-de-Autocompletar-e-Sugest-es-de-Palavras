# **Sistema de Autocompletar e Sugest√µes de Palavras**

Atividade para a disciplina de Algoritmos e Estruturas de Dados II. <br/>

## üéØObjetivo 

Neste trabalho, o objetivo √© criar um sistema que possibilite a funcionalidade de autocompletar e oferecer sugest√µes de palavras aos usu√°rios. Nessa implementa√ß√£o √© utilizado uma estrutura da √°rvore bin√°ria como base. Al√©m disso, foi desenvolvido a √°rvore AVL e o algoritmo de Huffman para fins comparativos de execu√ß√£o.
O objetivo √© estabelecer uma rela√ß√£o entre as palavras dos textos de acordo com suas ocorr√™ncias e as palavras de pesquisa.

## üóÇÔ∏èEstrutura 

- ```document.hpp:``` Apresenta a struct ```WordInfo``` e ```AVL```inclus√£o das bibliotecas usadas.
- ```document.cpp:``` Desenvolvimento das fun√ß√µes de leitura dos arquivos e constru√ß√£o do heap e do arquivo output.    
- ```document.hpp:``` Apresenta a struct ```No``` e ```Huffman```.
- ```document.cpp:``` Desenvolvimento das fun√ß√µes da √°rvore bin√°ria, da AVL e do algoritmo de Huffman.  
- ```main.cpp:``` Chamada das fun√ß√µes usadas e o tempo de execu√ß√£o do programa.
- ```input.txt:``` Palavras de busca. 
- ```stopwords.txt:``` Artigos e conjun√ß√µes como (a, o, as, os, e, ou).
- ```output.txt``` Arquivo de sa√≠da. 
- Outros arquivos contidos dentro da pasta ```data```se referem aos textos de entrada.

## üíªResumo

A abordagem consistir√° em tr√™s etapas diferentes:

1. **√Årvore Bin√°ria Padr√£o**: Ser√° implementado uma √°rvore bin√°ria tradicional, selecionando as palavras mais relevantes e relacionadas √† pesquisa em cada texto. 
A relev√¢ncia de uma palavra ser√° determinada por sua frequ√™ncia e proximidade √† palavra de pesquisa.
2. **√Årvore AVL**: Ser√° implementado uma √°rvore AVL e repetiremos o processo de an√°lise.
3. **Codifica√ß√£o de Huffman**: Ser√° implementado o c√≥digo de Huffman para otimizar a √°rvore bin√°ria padr√£o. Ser√° calculado c√≥digos para cada palavra que posteriormente ser√£o organizadas na
estrutura da √°rvore com base nesses c√≥digos.

## ‚úîÔ∏èDiretrizes 

As especifica√ß√µes a seguir foram propostas para discuss√£o do problema:

- Os textos de entrada s√£o lidos independente do nome e os nomes s√£o armazenados em uma ```list<string>nameFiles```.
- As palavras do arquivo ```√¨nput``` s√£o lidas e armazenadas em uma ```list<string>wordInput```.
- O conte√∫do do arquivo de ```stopwords```, pode ser alterado de acordo com a prefer√™ncia do usu√°rio, desde que cada palavra esteja em uma linha do arquivo. 
- As stop words que forem encontradas em cada texto, s√£o em seguida exclu√≠das dele. Pois, por serem artigos e conjun√ß√µes facilmente seriam as mais frequentes do heap, no entanto foram desconsideradas.
- O nome do arquivo ```stopwords.txt``` n√£o deve ser alterado.

- Inicialmente o algoritmo percorre a lista com o nome dos arquivos, e para cada texto que √© aberto, os seguintes procedimentos ocorrem:

- O algoritmo realiza a leitura dele e cria uma tabela de dispers√£o (hash) intitulada ```glossary```, para contar quantas vezes cada palavra aparece no texto. A chave do hash √© a pr√≥pria palavra e o valor s√£o as ocorr√™ncias, armazenadas em uma struct denominada ```WordInfo```.

- Em seguida, a partir de um valor K, √© inserido em um vetor intitulado ```heap``` as primeiras K palavras guardadas no hash e depois s√£o organizadas de forma que a menor ocorr√™ncia das K palavras inseridas, esteja na primeira posi√ß√£o do vetor.
- Ap√≥s isso para cada elemento restante no hash, √© realizado compara√ß√µes com o menor valor contido no heap, esses valores s√£o as ocorr√™ncias:

  1. Se a ocorr√™ncia for maior do que o menor valor da heap, o menor valor √© removido, o novo elemento √© inserido e a estrutura novamente organizada.
  2. Caso contr√°rio, o elemento deve ser ignorado, e √© comparado o pr√≥ximo dado at√© o fim do gloss√°rio.
- No final, a heap conter√° os K elementos com maiores valores (ocorr√™ncias) dentre os textos lidos. 

- Ap√≥s isso, outro looping inicia para a lista de palavras a serem buscadas, para cada palavra do input os seguintes procedimentos ocorrem:
  1. √â verificado se a palavra est√° no texto, se n√£o estiver ela √© ignorada e √© processado a pr√≥xima palavra. Se estiver, o pr√≥ximo comando ser√°:

  2. √â verificado se a palavra est√° no heap, se sim, ela √© retirada dele. Se n√£o, o menos elemento do heap √© tirado.
  3. √â criada a √°rvore bin√°ria.
  4. √â criada a √°rvore AVL.
  5. √â criada a √°rvore a partir do c√≥digo de Huffman.

As √°rvores criadas ter√£o a mesma quantidade de elementos que o valor de ```K```e cada n√≥ √© uma posi√ß√£o do heap, com palavra e ocorr√™ncia.

- Depois desses passos, o gloss√°rio √© limpado e todas as √°rvores e o heap s√£o exclu√≠dos.
- Em seguida, √© processado o pr√≥ximo texto, repetindo o mesmo procedimento at√© que todos sejam lidos.
- Quando todos forem lidos, o algoritmo finaliza o output e encerra o programa.

De modo geral, para cada texto √© buscado uma lista de palavras e para cada uma presente no texto, ela ter√° 3 tipos de estruturas em √°rvore.

- Os textos de entrada s√£o lidos caracter por caracter, e utiliza-se um switch case para identificar o in√≠cio e o fim das palavras.
- As palavras que cont√©m h√≠fen, tiveram o h√≠fen removido. Por exemplo "arco-√≠ris" passa a ser "arco√≠ris".
- O valor da vari√°vel ```K```pode ser alterado, por√©m sempre deve ser um valor com uma unidade a mais do que se deseja mostrar
  exemplo: Para um heap de tamanho 20, o valor de K dever√° ser 21.
- 

## üìùDecis√µes de implementa√ß√£o  

### heap
O algoritmo implementa uma min-heap, ou seja, cada n√≥ tem um valor menor ou igual ao valor de seus filhos, mantendo o menor elemento na primeira posi√ß√£o. Os valores a serem armazenados nessa estrutura s√£o as maiores ocorr√™ncias de palavras no texto. Dessa forma. √© coletado as K palavras com maiores ocorr√™ncias. Cada texto ir√° ter um heap.

Custo Computacional: <br>
$O$  $n(log$ $k)$, onde $n$ √© o tamanho da cole√ß√£o de dados e $k$ o n√∫mero de itens mais relevantes.
<br>

### √Årvore Bin√°ria

Uma √°rvore bin√°ria √© uma estrutura de dados hier√°rquica composta por n√≥s, em que cada n√≥ pode ter, no m√°ximo, dois filhos: um filho √† esquerda e um filho √† direita. Quando a √°rvore est√° vazia, o valor da raiz √© NULL. Cada n√≥ de uma √°rvore bin√°ria consiste em tr√™s partes:

1. Dados: Armazena as informa√ß√µes associadas ao n√≥, nessa caso uma struct ```WordInfo```com a palavra e a ocorr√™ncia.
1. Ponteiro para o filho esquerdo.
1. Ponteiro para o filho direito.

Propriedades de uma √°rvore:

- N√≥: Cada elemento em uma √°rvore bin√°ria √© chamado de "n√≥" que cont√©m um dado, e pode ter at√© dois filhos.
- Raiz: O n√≥ superior de uma √°rvore bin√°ria √© chamado de "raiz". √â o ponto de partida da √°rvore.
- Filho: Cada n√≥ em uma √°rvore bin√°ria pode ter no m√°ximo dois filhos, que s√£o outros n√≥s que descendem dele.
- Pai: Cada n√≥, exceto a raiz, tem um n√≥ pai, que √© o n√≥ do qual ele √© descendente direto.
- Folha: Os n√≥s que n√£o t√™m filhos s√£o chamados de "folhas". S√£o os n√≥s terminais da √°rvore.
- Sub√°rvore: Uma sub√°rvore √© uma √°rvore bin√°ria que faz parte de uma √°rvore maior. Por exemplo, a sub√°rvore enraizada em um n√≥ filho √© uma √°rvore por si s√≥.
- Altura: A altura de uma √°rvore √© o comprimento do caminho mais longo da raiz at√© uma de suas folhas. √â uma medida da profundidade da √°rvore.

- A regra b√°sica para inser√ß√£o √©: Dado um n√≥ qualquer, se o valor a ser inserido for menor ou igual ao n√≥, o item ir√° para a esquerda e se for um valor maior que o n√≥ o item vai para direita.

Custo Computacional: $O$ $(n)$
#### Exemplo da inser√ß√£o deste m√©todo 
<br>

<div style="display: flex; justify-content: center;">
    <img src="img/tree.gif" width="500" height="250">
</div>

### AVL

A √°rvore AVL √© uma √°rvore de pesquisa bin√°ria balanceada. As diferen√ßas entre as alturas das sub√°rvores esquerda e direita para cada n√≥ s√£o menores ou iguais a 1.
Esse equil√≠brio √© mantido por meio de ```rota√ß√µes```, podendo elas serem simples ou duplas.<br>
Para cada n√≥ √© calculado a dist√¢ncia dele at√© seu √∫ltimo n√≥ (folha). Para o lado direito √© recebido valores positivos e para o lado esquerdo os negativos. O sinal da diferen√ßa entre os valores indica para qual lado a √°rvore est√° desequilibrada e deve girar.

Se o sinal do n√≥ pai, com o n√≥ filho, ambos forem positivos, a rota√ß√£o ocorre para ```direita```
Se o sinal do n√≥ pai, com o n√≥ filho, ambos forem negativos, a rota√ß√£o ocorre para ```esquerda```
Se o sinal do n√≥ pai, com o n√≥ filho, forem diferentes, ocorre uma ```rota√ß√£o dupla``` que pode ser ```rota√ß√£o dupla para direita``` e ```rota√ß√£o dupla para esquerda``` ou o contr√°rio.

Sua estrutura cont√©m o dado, ponteiros para esquerda e direita assim como na estrutura anterior, com o acr√©cimo de uma v√°riavel ```altura```em cada n√≥.

Custo Computacional:
A maioria das opera√ß√µes do BST (por exemplo, pesquisar, inserir, excluir, etc.) leva tempo $O(h)$, onde $h$ √© a altura do BST. O custo dessas opera√ß√µes pode se tornar $O(n)$ para uma √°rvore bin√°ria distorcida. Se nos certificarmos de que a altura da √°rvore permanece $O$ $log(n)$ ap√≥s cada inser√ß√£o e exclus√£o, ent√£o podemos garantir um limite superior de $O$ $log(n)$ para todas essas opera√ß√µes. A altura de uma √°rvore AVL √© sempre $O$$($log$ $(n)$ )$ onde $n$ √© o n√∫mero de n√≥s na √°rvore.

#### Exemplo da inser√ß√£o deste m√©todo

|           |           |
| --------- | --------- |
| <img src="img/1.png" alt="Descri√ß√£o da imagem 1" width="500"> | <img src="img/2.png" alt="Descri√ß√£o da imagem 2" width="500"> |
| <img src="img/3.png" alt="Descri√ß√£o da imagem 3" width="500"> | <img src="img/4.png" alt="Descri√ß√£o da imagem 4" width="500"> |
| <img src="img/5.png" alt="Descri√ß√£o da imagem 5" width="500"> | <img src="img/6.png" alt="Descri√ß√£o da imagem 6" width="500"> |


### C√≥difica√ß√£o de Huffman

O algoritmo de codifica√ß√£o de Huffman √© um m√©todo de compress√£o de dados que √© amplamente utilizado na compacta√ß√£o de informa√ß√µes. √â √∫til para compactar os dados nos quais h√° caracteres (palavras) que ocorrem com frequ√™ncia. Foi desenvolvido pela primeira vez por David Huffman.
Dado o heap, a tarefa √© encontrar c√≥digos Huffman para cada palavra. Funciona da seguinte maneira:

1. Os dados s√£o organizados em ordem crescente de frequ√™ncia e armazenados em uma fila de prioridade.
2. Cria-se um n√≥ vazio x. A primeira frequ√™ncia m√≠nima se torna filho esquerdo de x e a segunda frequ√™ncia m√≠nima ao filho direito de x. <br>
  O valor de x ser√° a soma das duas frequ√™ncias m√≠nimas acima.
3. Essas duas ocorr√™ncias utilizadas s√£o removidas, e x √© adicionada de volta na fila, troca-se dois n√≥s por um √∫nico.
4. O processo se repete at√© que reste apenas um elemento na fila.
5. Por fim, se tem a √°rvore montada.
6. Para os n√≥s filhos a esquerda √© atribu√≠do o valor ```0```.
7. Para os n√≥s filhos a direita √© atribu√≠do o valor ```1```.

- Cada palavra ter√° um c√≥digo formado por 0 e/ou 1.
- Para decodificar o c√≥digo, deve-se percorrer a √°rvore seguindo os bits no c√≥digo at√© chegar a uma folha, que corresponde a um elemento do conjunto de dados original.

Complexidade de tempo: $O$ $($ $n*log$ $n$ $)$ onde $n$ √© o n√∫mero de caracteres √∫nicos <br>
Espa√ßo Auxiliar: $O$ $(n)$

A codifica√ß√£o de Huffman leva tempo O (n log (n))
A complexidade de tempo do algoritmo de Huffman √© O(nlog(n)) onde n √© o n√∫mero de caracteres no texto. Os pesos na √°rvore correspondem √† frequ√™ncia de ocorr√™ncia do personagem. A abordagem gananciosa coloca os n caracteres em n sub√°rvores e come√ßa combinando os dois n√≥s de menor peso em uma √°rvore √† qual √© atribu√≠da a soma dos pesos dos dois n√≥s folha como o peso de seu n√≥ raiz.
Usando um heap para armazenar o peso de cada √°rvore, cada itera√ß√£o requer tempo O(log(n)) para determinar o peso mais barato e inserir o novo peso. Existem O(n) itera√ß√µes, uma para cada item.

#### Exemplo da inser√ß√£o deste m√©todo

|           |           |
| --------- | --------- |
| <img src="img/17.png" alt="Descri√ß√£o da imagem 17" width="280"> | <img src="img/18.png" alt="Descri√ß√£o da imagem 2" width="280"> |
| <img src="img/19.png" alt="Descri√ß√£o da imagem 3" width="280"> | <img src="img/20.png" alt="Descri√ß√£o da imagem 4" width="280"> |
| <img src="img/21.png" alt="Descri√ß√£o da imagem 5" width="280"> | <img src="img/22.png" alt="Descri√ß√£o da imagem 6" width="280"> |


## üíªCompara√ß√£o entre algoritmos

As √°rvores de busca bin√°ria podem ser bem aplicadas em algoritmos de ordena√ß√£o, ou ainda quando os dados t√™m uma hierarquia natural, podem ser usadas para representar essa hierarquia de forma eficiente e ainda como estruturas de dados que implementam dicion√°rios (tabelas de hash) podem usar a a≈ïvore bin√°ria para manter as chaves em ordem, permitindo a busca eficiente de chaves pr√≥ximas.
Por√©m, a falta de equil√≠brio √© uma desvantagem para as √°rvores bin√°rias, pois no pior caso, a altura da √°rvore pode ser O(n), resultando em complexidade de tempo de O(n) para as opera√ß√µes. <br> 
Pois a estrutura pode vir a ficar cada vez mais profunda, trazendo perca de desempenho.  

No entanto, o processo de balanceamento pode ser custoso em termos de desempenho, como na estrutura AVL, envolve a atualiza√ß√£o de ponteiros e valores em diferentes partes da √°rvore. Exigindo mais opera√ß√µes de rota√ß√£o e ajuste para cada novo n√≥ inserido ou removido.<br>
Aplica√ß√µes pr√°ticas das √°rvores AVL incluem e sistemas onde a efici√™ncia na manipula√ß√£o de dados √© crucial para o desempenho. Essas √°rvores garantem a estabilidade da estrutura, tornando-as valiosas em cen√°rios onde o equil√≠brio √© fundamental para o desempenho geral do sistema. P√≥rem para grande volume de dados, manter o custo das rota√ß√µes e de mais elementos para montar a estrutura, a AVL se torna menos vi√°vel de ser utilizada.

Entretanto, a frequ√™ncia de uma determinada informa√ß√£o em um grupo de dados pode ser revelante, no caso da codifica√ß√£o de Huffman, por exemplo, em ASCII, cada c√≥digo de caractere ocupa exatamente 8 bits. Na pr√°tica, nem todos os caracteres ocorrem com a mesma frequ√™ncia. A codifica√ß√£o Huffman tira vantagem disso e atribui c√≥digos menores para caracteres mais frequentes, em detrimento da atribui√ß√£o de c√≥digos maiores para caracteres menos frequentes. Ainda, nessa codifica√ß√£o n√£o existe outra palavra de c√≥digo que seja um prefixo de outra palavra de c√≥digo v√°lida. Torando-se uma implementa√ß√£o √∫til para Compacta√ß√£o de arquivos e Transmiss√£o de dados pela Internet, pois cada c√≥digo √© exclusivo para cada dado.

 ## üïúTempo de execu√ß√£o 

A contagem foi feita pelas ferramentas disponibilizadas pela bibioteca "time.h". <br/>
O algoritmo foi executado 10 vezes e obteve-se como m√©dia geral o tempo de: $      $ $ms$

## ‚úÖResultados 

No terminal √© mostrado apenas o tempo de execu√ß√£o.
A sa√≠da completa do programa est√° no arquivo ```output.txt``` que cont√©m:
Para cada texto, se a palavra aparecer √© mostrado:
- Sua frequ√™ncia, √°rvore bin√°ria e avl que mostram a palavra e sua ocorr√™ncia e a codifica√ß√£o de huffman que mostra a palavra e seu c√≥digo, correspondente a esse texto.
Se a palavra n√£o estiver no texto, nada sobre ela ser√° mostrado no output.



##  üìãConclus√£o 

Este projeto permitiu a explora√ß√£o e implementa√ß√£o de diferentes estruturas de dados e algoritmos em um contexto pr√°tico. Foi poss√≠vel observar as vantagens e desvantagens de cada uma dessas estruturas e algoritmos em rela√ß√£o √† tarefa de autocompletar e oferecer sugest√µes de palavras aos usu√°rios.
As √°rvores bin√°rias demonstraram ser eficazes para a busca e organiza√ß√£o de palavras, mas sua falta de balanceamento pode levar a um desempenho inferior em casos extremos. A √°rvore AVL, por outro lado, garante um equil√≠brio autom√°tico, tornando-a uma escolha s√≥lida quando a estabilidade da estrutura √© crucial.
A codifica√ß√£o de Huffman mostrou ser uma t√©cnica poderosa para otimizar a representa√ß√£o de palavras com base em sua frequ√™ncia, economizando espa√ßo e sendo √∫til em cen√°rios de compacta√ß√£o de dados.
Em termos de tempo de execu√ß√£o, os algoritmos apresentaram desempenho variado, com a √°rvore AVL e a codifica√ß√£o de Huffman oferecendo tempos de execu√ß√£o mais eficientes em compara√ß√£o com a √°rvore bin√°ria n√£o balanceada.


##  üëæCompila√ß√£o e Execu√ß√£o  

Esse pequeno exemplo possui um arquivo Makefile que realiza todo o procedimento de compila√ß√£o e execu√ß√£o. <br/>Para tanto, temos as seguintes diretrizes de execu√ß√£o:


| Comando                |  Fun√ß√£o                                                                                           |                     
| -----------------------| ------------------------------------------------------------------------------------------------- |
|  `make clean`          | Apaga a √∫ltima compila√ß√£o realizada contida na pasta build                                        |
|  `make`                | Executa a compila√ß√£o do programa utilizando o gcc, e o resultado vai para a pasta build           |
|  `make run`            | Executa o programa da pasta build ap√≥s a realiza√ß√£o da compila√ß√£o                                 |

## Refer√™ncias 

https://www.geeksforgeeks.org/insertion-in-an-avl-tree/ <br>
https://www.geeksforgeeks.org/huffman-coding-using-priority-queue/ <br>
https://www.geeksforgeeks.org/applications-advantages-and-disadvantages-of-binary-search-tree/ <br>
https://www.geeksforgeeks.org/insertion-in-an-avl-tree/ <br>

### Contato 
<div>
 <br><p align="justify"> Anna Laura Moura Santana</p>
 <a href="https://t.me/annalaurams">
 <img align="center" src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white"/> 
 </div>
<a style="color:black" href="mailto:nalauramoura@gmail.com?subject=[GitHub]%20Source%20Dynamic%20Lists">
‚úâÔ∏è <i>nalauramoura@gmail.com</i>
</a>
